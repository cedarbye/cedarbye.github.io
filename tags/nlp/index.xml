<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nlp on cedar&#39;s blog</title>
    <link>cedarbye.github.io/tags/nlp/</link>
    <description>Recent content in Nlp on cedar&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 24 Mar 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="cedarbye.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>分词算法——mmseg</title>
      <link>/cedarbye.github.io/post/2016/2016_03_24%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95_mmseg/</link>
      <pubDate>Thu, 24 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/cedarbye.github.io/post/2016/2016_03_24%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95_mmseg/</guid>
      <description>

&lt;p&gt;最大匹配算法的准确度似乎不高，啥正向最大匹配啊，说白了，就是拿着你的字典然后对文本进行暴力切割，这种算法切割出来的错误率肯定超级高，算法原理满大街都是，就不说了，时间复杂度倒挺低O(n)。&lt;/p&gt;

&lt;p&gt;接着就换算法，学习了个也比较简单的mmseg算法，这是台湾同胞提出来的，其实就是对正向最大匹配算法进行了优化，这里的优化不是指优化时间复杂度，是优化降低错误率的，但是也会出现很奇葩的错误，让人看了都蛋疼。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://technology.chtsai.org/mmseg/&#34;&gt;算法的原文&lt;/a&gt;，中文有翻译的。其实就是用了四个判断的法则，需要的可以查文档，这里略过&lt;/p&gt;

&lt;p&gt;算法的说明也是满大街都是,简单给个&lt;a href=&#34;http://www.byywee.com/page/M0/S602/602088.html&#34;&gt;博客&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;斯坦福大学有个具体的&lt;a href=&#34;http://nlp.stanford.edu/software/segmenter.shtml&#34;&gt;实现包&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里举个正向最大匹配和mmseg算法对同样的文本切割后的效果吧：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;南京市长江大桥欢迎您

&lt;ul&gt;
&lt;li&gt;正向最大匹配：南京/市长/江/大桥/欢迎您&lt;/li&gt;
&lt;li&gt;mmseg的方法：南京市/长江大桥/欢迎您&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;研究生命科学

&lt;ul&gt;
&lt;li&gt;正向最大匹配：研究生/命/科学&lt;/li&gt;
&lt;li&gt;mmseg的方法：研究/生命/科学&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;长春市长春药店

&lt;ul&gt;
&lt;li&gt;正向最大匹配：长春/市长/春药/店&lt;/li&gt;
&lt;li&gt;mmseg的方法：长春市/长春/药店&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;台湾国中学生

&lt;ul&gt;
&lt;li&gt;正向最大匹配：台湾国/中学生&lt;/li&gt;
&lt;li&gt;mmseg的方法：台湾/国中/学生&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;当然这些匹配的结果都取决于您的字典&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;mmseg方法:c66c89eb3c614731ea63bf4d9bea6b95&#34;&gt;mmseg方法&lt;/h1&gt;

&lt;h2 id=&#34;匹配方法:c66c89eb3c614731ea63bf4d9bea6b95&#34;&gt;&lt;strong&gt;匹配方法&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&#34;1-simple方法:c66c89eb3c614731ea63bf4d9bea6b95&#34;&gt;1. Simple方法&lt;/h3&gt;

&lt;p&gt;即简单的正向匹配，根据开头的字，列出所有可能的结果。&lt;/p&gt;

&lt;p&gt;比如“一个劲儿的说话”，可以得到&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;一个&lt;br /&gt;
一个劲&lt;br /&gt;
一个劲儿&lt;br /&gt;
一个劲儿的&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这四个匹配结果（假设这四个词都包含在词典里）。&lt;/p&gt;

&lt;h3 id=&#34;2-complex方法:c66c89eb3c614731ea63bf4d9bea6b95&#34;&gt;2. Complex方法&lt;/h3&gt;

&lt;p&gt;匹配出所有的“三个词的词组”（原文中使用了chunk，这里感觉用“词组”比较合适），即从某一既定的字为起始位置，得到所有可能的“以三个词为一组”的所有组合。&lt;/p&gt;

&lt;p&gt;比如“研究生命起源”，可以得到&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;研 \究 \生&lt;br /&gt;
研 \究 \生命&lt;br /&gt;
研究生 \命 \起源&lt;br /&gt;
研究 \生命 \起源&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这些“词组”（根据词典，可能远不止这些，仅此举例）&lt;/p&gt;

&lt;h2 id=&#34;消除歧义的规则:c66c89eb3c614731ea63bf4d9bea6b95&#34;&gt;&lt;strong&gt;消除歧义的规则&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&#34;1-maximum-matching-最大匹配:c66c89eb3c614731ea63bf4d9bea6b95&#34;&gt;1. Maximum matching (最大匹配)&lt;/h3&gt;

&lt;p&gt;有两种情况，分别对应于使用“simple”和“complex”的匹配方法。&lt;/p&gt;

&lt;p&gt;对“simple”匹配方法，选择长度最大的词，用在上文的例子中即选择“一个劲儿的”&lt;/p&gt;

&lt;p&gt;对“complex”匹配方法，选择“词组长度最大的”那个词组，然后选择这个词组的第一个词，作为切分出的第一个词，上文的例子中即“研究生 命 起源”中的“研究生”，或者“研究 生命 起源”中的“研究”。&lt;/p&gt;

&lt;h3 id=&#34;2-largest-average-word-length-最大平均词语长度:c66c89eb3c614731ea63bf4d9bea6b95&#34;&gt;2. Largest average word length（最大平均词语长度）&lt;/h3&gt;

&lt;p&gt;经过规则1过滤后，如果剩余的词组超过1个，那就选择平均词语长度最大的那个（平均词长＝词组总字数/词语数量）。&lt;/p&gt;

&lt;p&gt;比如“生活水平”，可能得到如下词组：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;生 \活水 \平 (&lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;=1.33)&lt;br /&gt;
生活 \水 \平 (&lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;=1.33)&lt;br /&gt;
生活 \水平 (&lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;=2)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;根据此规则，就可以确定选择“生活水平”这个词组&lt;/p&gt;

&lt;h3 id=&#34;3-smallest-variance-of-word-lengths-词语长度的最小变化率:c66c89eb3c614731ea63bf4d9bea6b95&#34;&gt;3. Smallest variance of word lengths（词语长度的最小变化率）&lt;/h3&gt;

&lt;p&gt;由于词语长度的变化率可以由&lt;a href=&#34;http://baike.baidu.com/view/78339.htm&#34;&gt;标准差&lt;/a&gt;反映，所以此处直接套用标准差公式即可。&lt;/p&gt;

&lt;p&gt;比如:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;研究 \生命 \起源 （标准差=sqrt(((2-2)^2+(2-2)^2+(2-2^2))/3)=0）&lt;br /&gt;
研究生 \命 \起源 （标准差=sqrt(((2-3)^2+(2-1)^2+(2-2)^2)/3)=0.8165）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;于是选择“研究 \生命 \起源”这个词组。&lt;/p&gt;

&lt;h3 id=&#34;4-largest-sum-of-degree-of-morphemic-freedom-of-one-character-words:c66c89eb3c614731ea63bf4d9bea6b95&#34;&gt;4. Largest sum of degree of morphemic freedom of one-character words&lt;/h3&gt;

&lt;p&gt;其中degree of morphemic freedom可以用一个数学公式表达：log(frequency)，即词频的自然对数（这里log表示数学中的ln）。这个规则的意思是“计算词组中的所有单字词词频的自然对数，然后将得到的值相加，取总和最大的词组”。&lt;/p&gt;

&lt;p&gt;比如：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;设施 \和服 \务&lt;br /&gt;
设施 \和 \服务&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这两个词组中分别有“务”和“和”这两个单字词，假设“务”作为单字词时候的频率是5，“和”作为单字词时候的频率是10，对5和10取自然对数，然后取最大值者，所以取“和”字所在的词组，即“设施 /和 /服务”。&lt;br /&gt;
也许会问为什么要对“词频”取自然对数呢？可以这样理解，词组中单字词词频总和可能一样，但是实际的效果并不同.&lt;/p&gt;

&lt;p&gt;比如:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A \BBB \C （单字词词频，A:3， C:7）&lt;br /&gt;
DD \E \F （单字词词频，E:5，F:5）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;表示两个词组，A、C、E、F表示不同的单字词，如果不取自然对数，单纯就词频来计算，那么这两个词组是一样的（3+7=5+5），但实际上不同的词频范围所表示的效果也不同，所以这里取自然对数，以表区分（ln(3)+ln(7) &amp;lt; ln(5)+ln(5)， 3.0445&amp;lt;3.2189）。&lt;/p&gt;

&lt;p&gt;这个四个过滤规则中，如果使用simple的匹配方法，只能使用第一个规则过滤，如果使用complex的匹配方法，则四个规则都可以使用。实际使用中，一般都是使用complex的匹配方法＋四个规则过滤。（simple的匹配方法实质上就是正向最大匹配，实际中很少只用这一个方法）。&lt;/p&gt;

&lt;p&gt;看到这里也许对MMSEG的分词方法有了一个大致的了解，正如文章开头所述，它是一个“直观”的分词方法。它把一个句子“尽可能长（这里的长，是指所切分的词尽可能的长）”“尽可能均匀”的区切分，稍微想象一下，便感觉与中文的语法习惯比较相符。如果对分词精度要求不是特别高，MMSEG是一个简单、可行、快速的方法。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;大家在看了上面的博客，理解了什么是mmseg算法再往下看&lt;br /&gt;
具体Python代码如下：&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;cedarbye.github.io/code/20160324/mmseg.py&#34;&gt;mmseg.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;此代码参照google code的一个代码，经过了我自己的修改和自己去其的理解&lt;br /&gt;
代码结构说明：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Word类就相当于C语言中的结构体，用来存单词和词频的&lt;br /&gt;
Chunk类是用来实现具体的切割判断方法的前期预处理计算的&lt;br /&gt;
ComplexCompare类是用来具体实现mmseg算法的四种评估方法的&lt;br /&gt;
有几个全局变量和全局函数是用来加载字典的，用全局是为了不让字典多次的加载&lt;br /&gt;
Analysis类是用来具体实现切割算法的&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面是测试代码&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;cedarbye.github.io/code/20160324/mmseg_test.py&#34;&gt;mmseg_test.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;转载自&lt;a href=&#34;http://www.aiuxian.com/article/p-1976364.html&#34;&gt;爱悠闲&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>